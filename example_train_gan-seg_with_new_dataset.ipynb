{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Train the entire pipeline with a new dataset\n",
    "This jupyter notebook shows how you can train your own GAN to generate synthetic images that fit your dataset. In step two, we then train a segmentation that is trained on your dataset and therefore maximizes performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example you will need:\n",
    "- A dataset of 2D 3x3 mmÂ² macular OCTA images. We recommend at least 200 good quality images, a resolution of >=304x304 pixel, and to only / mainly train on healthy samples.\n",
    "- An NVIDIA GPU compatible with CUDA version >= 8 and 30GB of VRAM\n",
    "- A clean [conda](https://docs.conda.io/en/main/miniconda.html) environment with python 3 and [pytorch](https://pytorch.org/get-started/locally/) (tested with python 3.10, pytorch==2.0.1, and torchvision==0.15.2)\n",
    "\n",
    "Install the required dependencies:\n",
    " > âš ï¸ **_NOTE:_** Package `open3d` is currently (Nov 22, 2023) not available for python 3.11 yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip istall -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for this notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n",
    "import os\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GAN training\n",
    "We first train a new GAN model to generate realistic synthetic images that fit your dataset. For this, you first need to configure a `config.yml` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Configure GAN config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./configs/config_gan_ves_seg.yml\", \"r\") as stream:\n",
    "    config: dict[str,dict] = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Enter the path to your dataset:\n",
    "YOUR_DATASET_PATH = ...\n",
    "\n",
    "# You may want to choose your own folder for this\n",
    "config[\"Output\"][\"save_dir\"] = os.path.abspath(\"./results/custom-gan-ves-seg\")\n",
    "\n",
    "# Your real OCTA images are used to train the GAN\n",
    "config[\"Train\"][\"data\"][\"real_B\"][\"files\"] = YOUR_DATASET_PATH\n",
    "# We use our existing dataset of synthetic vessel maps \n",
    "config[\"Train\"][\"data\"][\"real_A\"][\"files\"] = os.path.abspath(\"./datasets/vessel_graphs/*.csv\")\n",
    "# We use our existing dataset of synthetic vessel maps (Make sure that these are the same vessel maps!)\n",
    "config[\"Train\"][\"data\"][\"real_A_seg\"][\"files\"] = os.path.abspath(\"./datasets/vessel_graphs/*.csv\")\n",
    "# We use our existing dataset of synthetic background vessel maps.\n",
    "config[\"Train\"][\"data\"][\"background\"][\"files\"] = os.path.abspath(\"./datasets/background_images/*.png\")\n",
    "\n",
    "\n",
    "# We want to use the GAN part of this model during inference\n",
    "config[\"General\"][\"inference\"] = \"generator\"\n",
    "# We use our existing dataset of synthetic vessel maps \n",
    "config[\"Train\"][\"data\"][\"real_A\"][\"files\"] = os.path.abspath(\"./datasets/vessel_graphs/*.csv\")\n",
    "# We use our existing dataset of synthetic background vessel maps.\n",
    "config[\"Train\"][\"data\"][\"background\"][\"files\"] = os.path.abspath(\"./datasets/background_images/*.png\")\n",
    "\n",
    "# In case you want to segment your dataset with the implicitly trained segmentor, run the following:\n",
    "# config[\"General\"][\"inference\"] = \"segmentor\"\n",
    "# config[\"Test\"][\"real_B\"][\"files\"] = YOUR_DATASET_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(YOUR_DATASET_PATH, str), \"Please provide a valid path to your dataset\"\n",
    "dataset_paths = natsorted(glob(YOUR_DATASET_PATH))\n",
    "assert len(dataset_paths) > 0, \"No images found! Please check your path again.\"\n",
    "\n",
    "# Plot an example of your dataset\n",
    "Image.open(dataset_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your custom yaml file\n",
    "with open('./configs/my_custom_gan_config.yml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Train the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your custom config file\n",
    "CONFIG_FILE_PATH = os.path.abspath(\"./configs/my_custom_gan_config.yml\")\n",
    "# Number of cpu cores for dataloading. If not set, use half of available cores.\n",
    "NUM_WORKERS = None \n",
    "\n",
    "# Train a new Generator network\n",
    "!python train.py --config_file $CONFIG_FILE_PATH --num_workers $NUM_WORKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Validate you generator (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Enter the path of the config.yml file that was created during training.\n",
    "CONFIG_FILE_PATH: str = ...\n",
    "# TODO Enter the epoch you want to load a checkpoint from. In our paper, we use epoch 50 but this depends on your dataset.\n",
    "EPOCH: int = ...\n",
    "\n",
    "# For a simple test we will just create 3 images\n",
    "NUM_SAMPLES = 3\n",
    "# Number of cpu cores for dataloading. If not set, use half of available cores.\n",
    "NUM_WORKERS = None\n",
    "\n",
    "# Test your trained generator:\n",
    "!python test.py --config_file $CONFIG_FILE_PATH --epoch $EPOCH --num_workers $NUM_WORKERS --num_samples $NUM_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = glob(CONFIG_FILE_PATH.replace(\"config.yml\", \"Test/*.png\"))\n",
    "test_images = [Image.open(p) for p in test_image_paths]\n",
    "_, axes=plt.subplots(nrows=1, ncols=3, figsize=(9,3))\n",
    "for a,i in zip(test_images, axes):\n",
    "    a.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vessel segmentation training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained GAN, we can use it to augment our synthetic training images. We can now begin to train the segmentation network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Configure vessel segmentation config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> âš ï¸ **_NOTE:_** In the following we assume that you use the `config_ves_seg-S_GAN.yml` without changes. If you add further training data augmentations make sure that the index (normally 6) points to the `ImageToImageTranslationd` augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./configs/config_ves_seg-S_GAN.yml\", \"r\") as stream:\n",
    "    config: dict[str,dict] = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Enter the path to your generator checkpoint that you want to use\n",
    "GAN_CHECKPOINT_PATH = ...\n",
    "config[\"Train\"][\"data_augmentation\"][6] = GAN_CHECKPOINT_PATH\n",
    "\n",
    "# You may want to choose your own folder for this\n",
    "config[\"Output\"][\"save_dir\"] = os.path.abspath(\"./results/custom-ves-seg-S_GAN\")\n",
    "\n",
    "# We use our existing dataset of synthetic vessel maps \n",
    "config[\"Train\"][\"data\"][\"image\"][\"files\"] = os.path.abspath(\"./datasets/vessel_graphs/*.csv\")\n",
    "# We use our existing dataset of synthetic vessel maps (Make sure that these are the same vessel maps!)\n",
    "config[\"Train\"][\"data\"][\"label\"][\"files\"] = os.path.abspath(\"./datasets/vessel_graphs/*.csv\")\n",
    "# We use our existing dataset of synthetic background vessel maps.\n",
    "config[\"Train\"][\"data\"][\"background\"][\"files\"] = os.path.abspath(\"./datasets/background_images/*.png\")\n",
    "\n",
    "\n",
    "# Use can use your dataset for validation (altough this will not mean much without labels)\n",
    "config[\"Validation\"][\"data\"][\"image\"][\"files\"] = YOUR_DATASET_PATH\n",
    "config[\"Validation\"][\"data\"][\"image\"][\"split\"] = None\n",
    "\n",
    "# If you have labels for your dataset use them, otherwise you can just your dataset path. This will then use a threshold of 0.5 to create a dummy label map.\n",
    "config[\"Validation\"][\"data\"][\"image\"][\"files\"] = YOUR_DATASET_PATH\n",
    "config[\"Validation\"][\"data\"][\"image\"][\"split\"] = None\n",
    "\n",
    "# Use can use your dataset for inference\n",
    "config[\"Test\"][\"data\"][\"image\"][\"files\"] = YOUR_DATASET_PATH\n",
    "config[\"Test\"][\"data\"][\"image\"][\"split\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(config[\"Train\"][\"data\"][\"image\"][\"files\"], str), \"Please provide a valid path to your dataset training\"\n",
    "dataset_paths = natsorted(glob(config[\"Train\"][\"data\"][\"image\"][\"files\"]))\n",
    "assert len(dataset_paths) > 0, \"No images found! Please check your train path again.\"\n",
    "\n",
    "assert isinstance(config[\"Validation\"][\"data\"][\"image\"][\"files\"], str), \"Please provide a valid path to your validation dataset\"\n",
    "dataset_paths = natsorted(glob(config[\"Validation\"][\"data\"][\"image\"][\"files\"]))\n",
    "assert len(dataset_paths) > 0, \"No images found! Please check your validation path again.\"\n",
    "\n",
    "assert isinstance(config[\"Test\"][\"data\"][\"image\"][\"files\"], str), \"Please provide a valid path to your test dataset\"\n",
    "dataset_paths = natsorted(glob(config[\"Test\"][\"data\"][\"image\"][\"files\"]))\n",
    "assert len(dataset_paths) > 0, \"No images found! Please check your test path again.\"\n",
    "\n",
    "assert os.path.isfile(GAN_CHECKPOINT_PATH), \"The given patht to the generator checkpoint is not valid!\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your custom yaml file\n",
    "with open('./configs/my_custom_ves_seg_config.yml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Train the segmentation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your custom vessel segmentation config file\n",
    "CONFIG_FILE_PATH = os.path.abspath(\"./configs/my_custom_ves_seg_config.yml\")\n",
    "# Number of cpu cores for dataloading. If not set, use half of available cores.\n",
    "NUM_WORKERS = None \n",
    "\n",
    "# Train a new Generator network\n",
    "!python train.py --config_file $CONFIG_FILE_PATH --num_workers $NUM_WORKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Test the segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Enter the path of the config.yml file that was created during training.\n",
    "CONFIG_FILE_PATH: str = ...\n",
    "\n",
    "# Enter the epoch you want to load a checkpoint from. You can simply used 'latest' for now.\n",
    "EPOCH: str = \"latest\"\n",
    "# For a simple test we will just create 10 images. If you do not set this, all images will be segmented.\n",
    "NUM_SAMPLES = 10\n",
    "# Number of cpu cores for dataloading. If not set, use half of available cores.\n",
    "NUM_WORKERS = None\n",
    "\n",
    "# Test your trained generator:\n",
    "!python test.py --config_file $CONFIG_FILE_PATH --epoch $EPOCH --num_workers $NUM_WORKERS --num_samples $NUM_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = glob(CONFIG_FILE_PATH.replace(\"config.yml\", \"Test/*.png\"))\n",
    "test_images = [Image.open(p) for p in test_image_paths]\n",
    "_, axes=plt.subplots(nrows=1, ncols=3, figsize=(9,3))\n",
    "for a,i in zip(test_images, axes):\n",
    "    a.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you made it trough the example! ðŸŽ‰\n",
    "\n",
    "You can now start to optimize your pipeline. Possible things you might want to try next:\n",
    "- Select optimal GAN and segmentor checkpoints\n",
    "- Add further data augmentations\n",
    "- Change the GAN model\n",
    "- Experiment with other hyperparamers of our pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
